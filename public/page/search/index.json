[{"content":" Note: This blog post is based on my personal notes but rewritten and restructured by AI.\nChapter 2: Architectural Thinking This chapter explores the mindset shift necessary to think like a software architect. It centers on four core facets that define architectural thinking.\nArchitecture Versus Design Traditionally, architects focused on high-level concerns such as defining architectural characteristics (e.g., \u0026ldquo;-ilities\u0026rdquo;), selecting architectural patterns, and designing system components—the foundational \u0026ldquo;building blocks.\u0026rdquo; These artifacts were then \u0026ldquo;handed off\u0026rdquo; to development teams. Developers handled lower-level details, including class diagrams, UI screens, source code development, and testing. The chapter emphasizes that this \u0026ldquo;old-school Waterfall approach\u0026rdquo;—where architecture is static and rigid—no longer works. Modern architectures are dynamic and continuously evolving, requiring \u0026ldquo;tight collaboration between the architect and the development team.\u0026rdquo; The authors advocate breaking down \u0026ldquo;physical and virtual barriers\u0026rdquo; between architects and developers, fostering a \u0026ldquo;strong bidirectional relationship\u0026rdquo; where both are part of the \u0026ldquo;same virtual team.\u0026rdquo; This enables continuous synchronization because architecture and design are \u0026ldquo;deeply intertwined.\u0026rdquo; Technical Breadth Technical Breadth distinguishes a software architect\u0026rsquo;s knowledge from that of a developer.\nA developer needs deep expertise in a specific area, such as mastering a particular programming language or tool. An architect must have a broad understanding of many technologies and solutions, prioritizing knowledge of multiple ways to solve problems over deep expertise in a single technology. Knowledge can be visualized as a pyramid with three layers: Deep knowledge: What you know well (e.g., Java expertise for a Java developer). Known unknowns: Technologies you\u0026rsquo;ve heard of but aren\u0026rsquo;t expert in (e.g., awareness of Clojure). Unknown unknowns: Technologies or ideas you haven\u0026rsquo;t encountered but might be ideal solutions. As one transitions from developer to architect:\nThe focus shifts from depth to breadth. The top two layers (what you know and what you know you don\u0026rsquo;t know) become increasingly important. It\u0026rsquo;s normal to trade some depth for breadth. Why this matters: Architects who fail to broaden their knowledge risk falling into \u0026ldquo;stale expertise\u0026rdquo; or the \u0026ldquo;Frozen Caveman Anti-Pattern,\u0026rdquo; where outdated solutions persist simply due to familiarity.\nMaintaining breadth:\nAllocate time daily for learning new things (e.g., the \u0026ldquo;20-minute rule\u0026rdquo;). Use resources like InfoQ, DZone Refcardz, and the ThoughtWorks Technology Radar. Bottom line: Broad technical knowledge equips architects to identify more solutions and make smarter design decisions.\nAnalyzing Trade-Offs Architectural thinking requires recognizing and evaluating trade-offs in every solution.\n\u0026ldquo;Architecture is the stuff you can\u0026rsquo;t Google.\u0026rdquo; – Mark Richards\nThere is no universal \u0026ldquo;best\u0026rdquo; answer for architectural decisions because solutions depend on context, including deployment environment, business drivers, company culture, budget, timeframes, and team skills.\n\u0026ldquo;Programmers know the benefits of everything and the trade-offs of nothing. Architects need to understand both.\u0026rdquo; – Rich Hickey\n\u0026ldquo;There are no right or wrong answers in architecture—only trade-offs.\u0026rdquo; – Neal Ford\nFor example, choosing between topics (publish-subscribe) and queues (point-to-point) messaging in an auction system involves trade-offs:\nTopics offer greater extensibility and decoupling but sacrifice security, heterogeneous data support, and monitoring/scalability. The best choice depends on priorities like flexibility versus security or scalability versus ease of change. Key takeaway: Great architects weigh trade-offs carefully, selecting solutions that best fit their specific context rather than blindly adopting popular options.\nUnderstanding Business Drivers Architects must understand the business drivers underpinning a system\u0026rsquo;s success and translate these into architectural characteristics such as scalability, performance, and availability. This requires domain knowledge and collaboration with stakeholders to identify, qualify, and measure these characteristics against business needs.\nBalancing Architecture and Hands-On Coding Core Idea A successful architect maintains technical depth through hands-on coding while avoiding becoming a bottleneck.\nStrategies to Balance Coding and Architecture Avoid becoming a bottleneck:\nDo not own critical-path or framework code that slows team progress. Instead, code business functionality a few iterations ahead to: Stay connected to production code. Empower the team to own complex critical components. Relate to the team\u0026rsquo;s challenges. Stay hands-on without blocking development:\nBuild Proof-of-Concepts (POCs) to evaluate new technologies; always write production-quality code since POCs often evolve into the codebase. Address technical debt or architecture stories, which have lower priority. Fix bugs to understand system weaknesses while supporting the team. Automate repetitive tasks by creating scripts or tools (e.g., lint checks, refactoring tools, architecture compliance). Write architectural compliance tests using tools like ArchUnit or custom fitness functions. Conduct frequent code reviews to ensure architecture alignment and mentor developers. Author\u0026rsquo;s Key Message Architecture is not just about diagrams and meetings; continuous coding is essential to remain relevant and credible. Choose coding tasks that add value without impeding the team. Use coding to strengthen the system, guide the team, and keep skills sharp. This summary distills the chapter\u0026rsquo;s core concepts on architectural thinking, balancing breadth and depth, collaboration, trade-offs, and business alignment essential for effective software architecture.\n","date":"2025-08-23T00:00:00Z","image":"http://localhost:1313/post/fundamentals-software-architecture-chapter-2/image_hu_930a4d706093fa24.png","permalink":"http://localhost:1313/post/fundamentals-software-architecture-chapter-2/","title":"Architectural Thinking: Key Insights from Fundamentals of Software Architecture Chapter 2"},{"content":" Note: This article reflects my personal point of view and insights based on my development experience.\nThe structure, formatting, and language refinement were assisted by AI to ensure clarity and readability.\nJava has been a cornerstone of backend development for decades, powering everything from enterprise systems to cloud-native microservices. Kotlin, first released in 2011 and officially supported by Spring since 2017, offers a modern JVM alternative that has steadily gained traction among developers.\nIn 2025, both Java and Kotlin are mature, production-ready, and well-supported in the Spring ecosystem. But when starting a new project, it’s worth asking: which language provides more advantages today?\nBuilt-In Features vs. External Dependencies In Java, some advanced capabilities require additional libraries, such as:\njSpecify – for nullability annotations Vavr – for functional programming utilities Lombok – for reducing boilerplate code MapStruct – for object mapping These libraries are useful, but they add extra setup, dependency management, and potential compatibility issues over time.\nKotlin includes many similar capabilities natively. The result is:\nCleaner code with fewer dependencies Reduced maintenance overhead Consistent, “built-in” language-level support rather than relying on third-party solutions Tooling and Developer Experience Java has made great strides in reducing verbosity, particularly with features like records, var, and pattern matching. However, Kotlin takes this a step further with language constructs that are inherently more concise and expressive.\nThis difference is not just about avoiding getters and setters. Kotlin’s design encourages:\nDeclarative, readable code Fewer repetitive patterns A smoother learning curve for developers coming from modern languages Java’s Rapid Evolution — and Kotlin’s Advantage Java now follows a twice-yearly release cycle, which has brought meaningful improvements to the language. But some of Kotlin’s core features may take years to appear in Java — if they appear at all.\nBecause Kotlin runs on the JVM and is fully interoperable with Java, it benefits from JVM improvements and continues to add its own language features independently.\nKey Kotlin Features for Modern Spring Development Here are some Kotlin features that many teams find hard to give up once adopted:\nNull-Safety and Nullability – Built into the type system to prevent NullPointerException. Extension Functions – Add methods to existing classes without modifying them. Higher-Order Functions – Functional programming as a first-class citizen. Inline Functions \u0026amp; Lambdas with Receivers – Enable clean DSLs and reduce overhead. Data Classes – Concise, immutable by default, and with auto-generated methods. Default \u0026amp; Named Parameters – Avoids excessive constructor overloading. Smart Casts – Automatic safe casting without extra syntax. Destructuring Declarations – Unpack objects into variables easily. Top-Level Functions – Functions outside classes for cleaner APIs. Type Inference Everywhere – Less boilerplate, more clarity. Rich Standard Library for Collections – Expressive and powerful operations. Immutability by Default – Encourages safer and more predictable code. Conclusion When starting a new Spring project in 2025, both Java and Kotlin are solid choices.\nJava offers unmatched stability, a massive ecosystem, and rapid ongoing improvements. Kotlin provides modern language features, reduced boilerplate, and a developer experience that’s both concise and expressive from day one. For teams looking to balance productivity, readability, and long-term maintainability, Kotlin presents a compelling option — especially when building new services on top of the Spring framework.\n","date":"2025-08-10T00:00:00Z","image":"http://localhost:1313/post/kotlin-vs-java-2025/image_hu_154a78ebf5289f9f.png","permalink":"http://localhost:1313/post/kotlin-vs-java-2025/","title":"Kotlin vs. Java for New Spring Projects: A 2025 Perspective"},{"content":" Note: This blog post is based on my personal notes but rewritten and restructured by AI.\nSoftware architecture remains one of the most challenging fields to define clearly. Unlike traditional engineering disciplines with well-established career paths, software architecture is constantly evolving, making any rigid definition quickly obsolete. This exploration of Chapter 1 from \u0026ldquo;Fundamentals of Software Architecture\u0026rdquo; reveals why this ambiguity exists and what it means for modern software architects.\nThe Challenge of Definition The difficulty in defining software architecture isn\u0026rsquo;t accidental—it\u0026rsquo;s fundamental to the field itself. As Ralph Johnson eloquently puts it:\n\u0026ldquo;Architecture is about the important stuff… whatever that is.\u0026rdquo;\nThis seemingly vague statement actually captures a profound truth: architecture is inherently contextual. What\u0026rsquo;s architecturally significant in a high-frequency trading system differs vastly from what matters in a content management system.\nModern architects face additional complexity beyond traditional code concerns. They must collaborate with business teams, operations, and various organizational departments. The rise of DevOps has fundamentally changed how systems are built and operated, requiring architects to update their approaches accordingly.\nA Comprehensive Definition of Software Architecture Rather than settling for vague metaphors like \u0026ldquo;system blueprint,\u0026rdquo; the book provides a concrete definition built on four interconnected dimensions:\n1. Structure of the System This refers to the architectural style—microservices, layered architecture, microkernel, etc. However, simply stating \u0026ldquo;it\u0026rsquo;s a microservices architecture\u0026rdquo; tells only part of the story. The structure must be understood in conjunction with the other dimensions.\n2. Architecture Characteristics (The \u0026ldquo;-ilities\u0026rdquo;) These define the success criteria of a system and are generally orthogonal to functionality. Key characteristics include:\nPerformance: How fast the system responds Scalability: The system\u0026rsquo;s ability to handle increased load Elasticity: Dynamic scaling capabilities Availability: System uptime requirements Reliability: Consistency of system behavior These characteristics are crucial—a system might implement all required features perfectly but fail if it can\u0026rsquo;t meet performance or availability requirements.\n3. Architecture Decisions These are the rules that dictate system construction, acting as constraints that guide development teams. For example, in a layered architecture, a decision might restrict the presentation layer from directly accessing the database.\nArchitecture decisions can include formal exceptions called variances, typically managed by an Architecture Review Board (ARB) or chief architect when strict adherence would be counterproductive.\n4. Design Principles Unlike architecture decisions, design principles are guidelines rather than strict rules. They provide preferred approaches while allowing flexibility for specific circumstances. For instance, a principle might suggest asynchronous messaging for performance while permitting other protocols when appropriate.\nArchitecture vs. Design: Drawing the Line The boundary between architecture and design often blurs, but understanding the distinction is crucial:\nArchitecture Design Big-picture, high-impact decisions Local, low-impact decisions Often technology-agnostic More detailed and technology-specific Difficult to change Easier to modify Example: Choosing between microservices and a monolithic architecture is an architectural decision. Selecting Redis over Memcached for caching is a design detail.\nThe Eight Core Expectations of a Software Architect Regardless of title or job description, software architects face eight fundamental expectations:\n1. Make Architecture Decisions Architects should guide rather than dictate technology choices. Instead of mandating React.js, recommend \u0026ldquo;reactive-based frameworks\u0026rdquo; to give teams flexibility while maintaining architectural coherence.\nThe goal is enabling informed decisions based on architectural guidance—not imposing tools unless critical for achieving architectural qualities like scalability or performance.\n2. Continually Analyze the Architecture Regular system analysis is essential. What worked three years ago might not be optimal today. Without continuous review, systems can degrade as developers make changes that compromise performance or reliability.\nArchitects must examine not just technology and business alignment, but also testing and deployment processes—even if these aren\u0026rsquo;t explicitly in their job description.\n3. Keep Current with Latest Trends While developers must stay current with their daily technologies, architects face an even more critical requirement. Architectural decisions tend to be long-lasting and difficult to change, making trend awareness essential for future-proofing systems.\n4. Ensure Compliance with Decisions Architects must verify that development teams follow agreed-upon architecture decisions and design principles. If the architecture restricts database access to specific layers, everyone must adhere to this rule—even when shortcuts seem faster.\nThese decisions often support maintainability, scalability, and flexibility. Ignoring them can lead to system degradation or unexpected behavior.\n5. Diverse Exposure and Experience Modern architects need broad exposure to different technologies, platforms, and languages. Not deep expertise in everything, but sufficient understanding to grasp how systems interact and make informed trade-offs.\nThis requires stepping out of comfort zones and focusing on technical breadth over depth.\n6. Have Business Domain Knowledge Understanding the business domain is crucial for designing effective solutions and communicating with stakeholders. Without domain knowledge, architects struggle to grasp business needs or build trust with business teams.\nExample: A banking architect should understand financial concepts like interest rates, credit risk, and loan underwriting to design systems that meet real business needs and communicate effectively with executives.\n7. Possess Interpersonal Skills Technical brilliance alone isn\u0026rsquo;t sufficient. Architects need exceptional interpersonal skills including teamwork, facilitation, and leadership. Many technically competent architects fail due to poor communication or leadership abilities.\nSuccess comes from helping teams solve problems, supporting junior developers, and explaining complex designs in accessible terms.\n8. Understand and Navigate Politics Unlike developers who make localized decisions, architects make broad decisions affecting multiple teams—decisions that often face challenges. Understanding company politics and negotiation skills are essential for getting architectural changes approved and implemented.\nExample: Proposing database separation for better security might face pushback from teams whose work becomes more complex. Architects must explain benefits and negotiate with stakeholders to gain support.\nEngineering Practices: The Evolution of Software Development The relationship between software construction and architectural design has evolved significantly. Historical separation between architecture and development process has given way to integrated approaches.\nKey Distinctions Process: Team organization mechanics, meeting conduct, workflow management Engineering Practices: Process-agnostic, proven techniques with repeatable benefits (e.g., continuous integration) Historical Evolution The journey began with Extreme Programming (XP) in the early 1990s, questioning existing processes and focusing on:\nTest-first development Automation Continuous integration This evolution continued through Continuous Delivery and culminated in DevOps, where operations adopted engineering practices originally championed by XP.\nModern Importance Engineering practices are vital because software development lacks the predictability of mature engineering disciplines, particularly regarding structural changes and estimation due to \u0026ldquo;unknown unknowns.\u0026rdquo;\nArchitects often determine team engineering practices, ensuring architectural style and engineering practices form a \u0026ldquo;symbiotic mesh.\u0026rdquo; For example, microservices architecture assumes automated machine provisioning, testing, and deployment.\nThe Fundamental Laws of Software Architecture The First Law: Everything is a Trade-off \u0026ldquo;Everything in software architecture is a trade-off\u0026rdquo;\nArchitects must always consider opposing factors when making decisions. There are no simple, binary choices in architecture. If something appears to have no trade-offs, the trade-offs simply haven\u0026rsquo;t been identified yet.\nThe Second Law: Why Over How \u0026ldquo;Why is more important than how\u0026rdquo;\nUnderstanding the reasoning behind architectural choices is more crucial than knowing only structural elements. An architect might observe how a system is structured but struggle to explain why specific decisions were made.\nThis principle emerged from workshop exercises where only topology was captured, leading to poor understanding of decision rationale. The book emphasizes explaining the \u0026ldquo;why\u0026rdquo; behind decisions and advocates for techniques like Architecture Decision Records (ADRs) to capture important decisions and their trade-offs.\nConclusion Software architecture\u0026rsquo;s inherent complexity and contextual nature make it both challenging and fascinating. The field requires a unique blend of technical expertise, business acumen, and interpersonal skills. As the discipline continues evolving with new technologies and practices, understanding these fundamental concepts becomes increasingly important.\nThe engineering approach advocated in \u0026ldquo;Fundamentals of Software Architecture\u0026rdquo;—being practical, systematic, and focused on real-world results—provides a solid foundation for navigating this complex field. By understanding the four dimensions of architecture, the core expectations of architects, and the fundamental laws governing architectural decisions, we can better appreciate both the challenges and opportunities in modern software architecture.\nWhether you\u0026rsquo;re an aspiring architect or an experienced practitioner, these insights remind us that successful architecture isn\u0026rsquo;t just about technical decisions—it\u0026rsquo;s about understanding context, managing trade-offs, and effectively communicating the \u0026ldquo;why\u0026rdquo; behind our choices.\n","date":"2025-07-29T00:00:00Z","image":"http://localhost:1313/post/fundamentals-software-architecture-chapter-1/image_hu_968f7baf19bb114.png","permalink":"http://localhost:1313/post/fundamentals-software-architecture-chapter-1/","title":"Understanding Software Architecture: Key Insights from Fundamentals of Software Architecture Chapter 1"},{"content":" Info This blog post is based on my personal notes from reading Tidy First? by Kent Beck, rewritten and restructured by AI to create a polished and cohesive article. You can read my long notes from this link.\nTidy First? A Practical Guide to Cleaner, More Maintainable Code If you\u0026rsquo;ve ever stared at a messy codebase and wondered, \u0026ldquo;How do I even start fixing this?\u0026rdquo; then Tidy First? by Kent Beck is the book for you. As the creator of Extreme Programming and a pioneer of software patterns, Beck offers a practical, approachable guide to tidying up software—making it more readable, maintainable, and easier to change. In this blog post, I’ll summarize the key insights from Tidy First? and share why it’s a must-read for any developer looking to improve their craft.\nWhy Tidy First? Software development is a balancing act between delivering features and maintaining a codebase that doesn’t collapse under its own complexity. Beck introduces the concept of tidyings—small, incremental changes to a codebase’s structure that make future behavioral changes easier. These “teensy-weensy” refactorings aren’t about rewriting everything but about making deliberate, bite-sized improvements.\nThe core question of the book is: “I need to change this messy code—what do I do next?” Beck’s answer is to tidy first when it makes sense. Tidying isn’t about perfection; it’s about reducing friction for the next change. By focusing on small steps, you create a codebase that’s easier to understand and adapt, saving time and reducing stress in the long run.\nKey Lessons from Tidy First? The book is divided into four parts: an introduction, specific tidying techniques, managing the tidying process, and the theory behind software design. Here are some standout takeaways:\n1. Small, Safe Steps Are Powerful Beck emphasizes that tidying is about incremental improvements. Instead of massive overhauls, focus on small changes like:\nGuard Clauses: Add early return checks to simplify function logic and reduce nesting. Delete Dead Code: Remove unused code to declutter the codebase (trust version control to recover it if needed). Normalize Symmetries: Standardize inconsistent patterns, like lazy initialization, to improve readability. For example, instead of wrestling with a function like this:\n1 2 3 4 public User getUserData(int userId, boolean includePrivate, boolean includeSettings) { // Complex logic... return new User(); } Wrap it in a clearer interface:\n1 2 3 public User getPublicUserProfile(int userId) { return getUserData(userId, false, false); } This makes the code self-explanatory and easier to maintain.\n2. Separate Structure from Behavior One of Beck’s key insights is the distinction between structural changes (tidying the code’s organization) and behavioral changes (altering what the code does). He recommends keeping these separate in commits or pull requests to make reviews easier and reduce errors. For instance:\nTidy first when the mess blocks understanding or makes changes harder. Tidy after when cleanup is quick and the context is fresh. Tidy later for non-urgent improvements that add long-term value. This separation keeps your workflow clear and helps teammates focus on one type of change at a time.\n3. Understand the Economics of Code Beck dives into the economic principles behind software design, like time value (a feature delivered today is worth more than one delivered tomorrow) and optionality (keeping your options open for future changes). Tidying is an investment in optionality—it makes future changes cheaper and faster. However, over-tidying can waste time, so Beck advises balancing immediate needs with long-term flexibility.\n4. Coupling and Cohesion The book’s theoretical section explores coupling (how much one part of the code depends on another) and cohesion (grouping related elements together). Good design minimizes coupling to reduce cascading changes and maximizes cohesion to keep related code close. For example:\nMove declarations and initializations together to clarify a variable’s purpose. Extract helper functions to encapsulate clear, reusable logic. 5. Find Your Rhythm Tidying is most effective when done in short, focused bursts. Beck suggests alternating between tidying (minutes to an hour) and behavior changes. Over time, you’ll notice that 80% of changes happen in 20% of the codebase—so focus your tidying efforts there. This “paved path” approach ensures you’re cleaning where it matters most.\nWhy You Should Read Tidy First? Tidy First? is more than a technical manual; it’s a mindset shift. Beck’s approachable style and focus on small, practical steps make it accessible for developers at all levels. Whether you’re untangling a legacy codebase or refining a new project, the book equips you with tools to:\nMake code easier to read and change. Balance immediate feature delivery with long-term maintainability. Feel more confident and joyful in your programming work. Beck’s emphasis on “helping geeks feel safe in the world” resonates deeply. Tidying isn’t just about code—it’s about reducing stress, boosting clarity, and creating a codebase that supports you and your team.\nFinal Thoughts Tidy First? is a refreshing take on software design that prioritizes practicality and human experience. By focusing on small, intentional tidyings, you can transform messy code into something that’s easier to work with and more enjoyable to maintain. If you’re ready to take control of your codebase and make programming feel less like a battle, give this book a read. It’s like cleaning your desk before starting a big project—sometimes, a little tidying goes a long way.\nHave you tried tidying your code before making changes? Share your thoughts in the comments below!\n","date":"2025-07-13T00:00:00Z","image":"http://localhost:1313/post/tidy-first/image_hu_2dddbeec4d30e65e.png","permalink":"http://localhost:1313/post/tidy-first/","title":"Summarizing Tidy First Book"},{"content":"Are you building a REST API with Go and Chi router? One of the most crucial aspects of API development is proper documentation. In this comprehensive guide, I\u0026rsquo;ll walk you through the process of integrating Swagger (OpenAPI) documentation into your Go project using Chi router. You\u0026rsquo;ll learn not just the basics, but also best practices and advanced techniques to create professional API documentation.\nWhy Swagger Documentation? Before diving into the implementation, let\u0026rsquo;s understand why Swagger documentation is essential:\nInteractive Documentation: Provides a user-friendly interface for API exploration Automatic Client Generation: Generate client libraries in multiple languages Testing Interface: Test API endpoints directly from the browser Industry Standard: Widely adopted OpenAPI specification Always Up-to-Date: Documentation generated from code annotations stays synchronized Required Dependencies Let\u0026rsquo;s start by setting up the necessary packages:\n1. swaggo/swag 1 go install github.com/swaggo/swag/cmd/swag@latest This core package provides:\nSwagger/OpenAPI 2.0 documentation generation from Go annotations CLI tooling for documentation management Automatic swagger.json and swagger.yaml file creation Support for complex types and nested structures 2. swaggo/http-swagger 1 go get -u github.com/swaggo/http-swagger This package offers:\nSwagger UI handler specifically for Chi router Browser-based API testing interface Lightweight integration capabilities 3. swaggo/files 1 go get -u github.com/swaggo/files A utility package that:\nManages static files for Swagger UI Handles efficient file serving Integrates seamlessly with http-swagger Project Structure For optimal organization, structure your project like this:\n1 2 3 4 5 project-root/ ├── docs/ # Auto-generated Swagger files ├── cmd/ │ └── main.go # Application entry point └── internal/ # Core application code Implementation Guide 1. Main API Documentation Start by adding the main API documentation annotations in your main.go:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Package main Yadwy Backend API // @title Your API Name // @version 1.0 // @description Your API description // @termsOfService http://swagger.io/terms/ // @contact.name API Support // @contact.email support@yourapi.com // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html // @host localhost:3000 // @BasePath / // @schemes http https // @securityDefinitions.apikey BearerAuth // @in header // @name Authorization // @description Enter the token with the `Bearer: ` prefix package main 2. Router Setup Configure your Chi router to serve Swagger documentation:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import ( httpSwagger \u0026#34;github.com/swaggo/http-swagger\u0026#34; _ \u0026#34;your-project/docs\u0026#34; // Required for swagger docs ) func SetupRouter() http.Handler { r := chi.NewRouter() // Swagger endpoint r.Get(\u0026#34;/swagger/*\u0026#34;, httpSwagger.Handler( httpSwagger.URL(\u0026#34;/swagger/doc.json\u0026#34;), )) return r } 3. Document Your Endpoints Here\u0026rsquo;s how to document your API endpoints effectively:\n1 2 3 4 5 6 7 8 9 10 11 12 // @Summary Create user // @Description Create a new user in the system // @Tags users // @Accept json // @Produce json // @Param user body CreateUserRequest true \u0026#34;User information\u0026#34; // @Success 201 {object} CreateUserResponse // @Failure 400 {object} ErrorResponse // @Router /users [post] func (h *Handler) CreateUser(w http.ResponseWriter, r *http.Request) { // Implementation } 4. Model Documentation Document your data models with clear examples:\n1 2 3 4 5 6 7 // User represents the user model type User struct { ID int64 `json:\u0026#34;id\u0026#34; example:\u0026#34;1\u0026#34;` Email string `json:\u0026#34;email\u0026#34; example:\u0026#34;user@example.com\u0026#34;` Name string `json:\u0026#34;name\u0026#34; example:\u0026#34;John Doe\u0026#34;` CreatedAt time.Time `json:\u0026#34;created_at\u0026#34;` } Best Practices 1. Organized Documentation Group related endpoints using tags Maintain consistent naming conventions Structure documentation hierarchically 2. Comprehensive Examples Provide realistic data examples Include both success and error scenarios Show different use cases 3. Error Documentation Document all possible error responses Include error codes and messages Explain error recovery steps 4. Security Documentation Clearly document authentication methods Specify required headers and tokens Include authorization scopes Maintenance Tips Keep Documentation Updated\nRun swag init after API changes Review generated documentation Update examples regularly Version Control\nCommit generated docs with code Track API changes systematically Maintain documentation versions Testing Your Documentation Access your Swagger UI:\nNavigate to http://localhost:8080/swagger/ Test endpoints interactively Verify documentation accuracy Validate Documentation:\nReview generated swagger.json Ensure all endpoints are documented Check for missing information Benefits of This Approach Documentation Quality\nAlways synchronized with code Interactive and user-friendly Professional presentation Development Efficiency\nFaster API development Clear endpoint structure Better team collaboration Client Integration\nEasy client code generation Multiple language support Reduced integration time Conclusion Integrating Swagger documentation into your Go + Chi project is a valuable investment that pays off in better API understanding, faster development, and improved collaboration. By following this guide and best practices, you\u0026rsquo;ll create professional, maintainable API documentation that enhances your project\u0026rsquo;s value.\nRemember to keep your documentation up-to-date and utilize the interactive features of Swagger UI for testing and validation. The effort you put into good documentation will be appreciated by both your team members and API consumers.\nHappy coding!\n","date":"2025-06-11T00:00:00Z","image":"http://localhost:1313/post/complete-guide-swagger-go-chi/image_hu_144a1b64d7f29811.png","permalink":"http://localhost:1313/post/complete-guide-swagger-go-chi/","title":"Complete Guide: Adding Swagger to Go + Chi Project"},{"content":"Command Query Responsibility Segregation (CQRS) is an architectural pattern that separates read and write operations for a data store. In this post, we\u0026rsquo;ll explore CQRS implementation in Java with practical examples.\nWhat is CQRS? CQRS stands for Command Query Responsibility Segregation. The main concept is to separate the read and write operations of your application:\nCommands: Handle write operations (create, update, delete) Queries: Handle read operations (fetch, search, list) This separation allows you to optimize each path independently and scale them according to their specific needs.\nBasic CQRS Implementation in Java Let\u0026rsquo;s implement a simple CQRS pattern for a product management system.\nDomain Model 1 2 3 4 5 6 7 8 public class Product { private String id; private String name; private BigDecimal price; private int stock; // Constructor, getters, and setters } Command Models 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CreateProductCommand { private String name; private BigDecimal price; private int initialStock; // Constructor, getters, and setters } public class UpdateStockCommand { private String productId; private int stockDelta; // Constructor, getters, and setters } Query Models 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class ProductQuery { private String id; public ProductQuery(String id) { this.id = id; } public String getId() { return id; } } public class ProductDto { private String id; private String name; private BigDecimal price; private int availableStock; // Constructor, getters, and setters } Command Handlers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Service public class ProductCommandHandler { private final ProductRepository repository; public ProductCommandHandler(ProductRepository repository) { this.repository = repository; } public String handle(CreateProductCommand command) { Product product = new Product( UUID.randomUUID().toString(), command.getName(), command.getPrice(), command.getInitialStock() ); repository.save(product); return product.getId(); } public void handle(UpdateStockCommand command) { Product product = repository.findById(command.getProductId()) .orElseThrow(() -\u0026gt; new ProductNotFoundException(command.getProductId())); product.setStock(product.getStock() + command.getStockDelta()); repository.save(product); } } Query Handlers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service public class ProductQueryHandler { private final ProductReadRepository readRepository; public ProductQueryHandler(ProductReadRepository readRepository) { this.readRepository = readRepository; } public ProductDto handle(ProductQuery query) { return readRepository.findById(query.getId()) .map(this::toDto) .orElseThrow(() -\u0026gt; new ProductNotFoundException(query.getId())); } private ProductDto toDto(Product product) { return new ProductDto( product.getId(), product.getName(), product.getPrice(), product.getStock() ); } } Benefits of CQRS Independent Scaling: Read and write workloads can be scaled independently. Optimized Data Schemas: Read and write models can be optimized for their specific uses. Better Security: Finer-grained control over access to read and write operations. Improved Performance: Each side can be tuned without affecting the other. Advanced CQRS with Event Sourcing For more complex applications, CQRS is often combined with Event Sourcing. Here\u0026rsquo;s a basic example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public interface Event { String getAggregateId(); LocalDateTime getTimestamp(); } public class ProductCreatedEvent implements Event { private final String aggregateId; private final String name; private final BigDecimal price; private final int initialStock; private final LocalDateTime timestamp; // Constructor, getters } public class StockUpdatedEvent implements Event { private final String aggregateId; private final int stockDelta; private final LocalDateTime timestamp; // Constructor, getters } @Service public class EventSourcingProductCommandHandler { private final EventStore eventStore; public String handle(CreateProductCommand command) { String productId = UUID.randomUUID().toString(); ProductCreatedEvent event = new ProductCreatedEvent( productId, command.getName(), command.getPrice(), command.getInitialStock(), LocalDateTime.now() ); eventStore.store(event); return productId; } public void handle(UpdateStockCommand command) { StockUpdatedEvent event = new StockUpdatedEvent( command.getProductId(), command.getStockDelta(), LocalDateTime.now() ); eventStore.store(event); } } Best Practices Start Simple: Don\u0026rsquo;t implement CQRS unless you need it. Simple CRUD operations might be sufficient for basic applications. Consider Eventual Consistency: In distributed systems, accept that read models might be slightly outdated. Use Event Sourcing Carefully: While powerful, it adds complexity. Use it when you need audit trails or complex event replay. Monitor Performance: Keep track of both read and write performance separately. Conclusion CQRS is a powerful pattern that can help scale and maintain complex applications. While it adds some complexity, the benefits of separated read and write concerns can be substantial for the right use case. Start with a simple implementation and evolve as needed.\nRemember that CQRS isn\u0026rsquo;t a silver bullet - it\u0026rsquo;s most beneficial in complex domains where the read and write requirements differ significantly. For simpler applications, traditional CRUD approaches might be more appropriate.\n","date":"2025-06-11T00:00:00Z","image":"http://localhost:1313/post/understanding-cqrs-pattern/image_hu_595c272c0d0d1514.png","permalink":"http://localhost:1313/post/understanding-cqrs-pattern/","title":"Understanding CQRS Pattern with Java Examples"},{"content":"Let me explain why I don\u0026rsquo;t like ORMs. They add a lot of abstraction, especially if you\u0026rsquo;re already working with Java and Spring, which have tons of abstraction layers. Yes, ORMs are useful and powerful, but as the saying goes, with great power comes great responsibility. Here\u0026rsquo;s an example to illustrate my point:\nOne of the unclear things when you work with JPA and Hibernate is the saveAll() method. Many of us might think it does batch inserts by default, but it doesn\u0026rsquo;t. Even when you think you\u0026rsquo;ve configured it correctly, it often still doesn\u0026rsquo;t work as expected.\nFor example, look at this code:\n1 2 3 4 5 6 7 8 9 10 public void batchInsert() { var list = List.of( new User(\u0026#34;nerd1\u0026#34;, \u0026#34;n1@nerd.com\u0026#34;), new User(\u0026#34;nerd2\u0026#34;, \u0026#34;n2@nerd.com\u0026#34;), new User(\u0026#34;nerd3\u0026#34;, \u0026#34;n3@nerd.com\u0026#34;), new User(\u0026#34;nerd4\u0026#34;, \u0026#34;n4@nerd.com\u0026#34;), new User(\u0026#34;nerd5\u0026#34;, \u0026#34;n5@nerd.com\u0026#34;) ); userRepository.saveAll(list); } At first look, you might think it performs a batch insert, but in reality, if you enable Hibernate statistics to see what\u0026rsquo;s going on under the hood, you\u0026rsquo;ll find it inserts records one by one:\n1 spring.jpa.properties.hibernate.generate_statistics=true Here\u0026rsquo;s the log output:\n1 2 3 4 5 6 7 8 9 10 11 796598 nanoseconds spent acquiring 1 JDBC connections; 0 nanoseconds spent releasing 0 JDBC connections; 8030421 nanoseconds spent preparing 5 JDBC statements; 5369411 nanoseconds spent executing 5 JDBC statements; 0 nanoseconds spent executing 0 JDBC batches; 0 nanoseconds spent performing 0 L2C puts; 0 nanoseconds spent performing 0 L2C hits; 0 nanoseconds spent performing 0 L2C misses; 3607503 nanoseconds spent executing 1 flushes (flushing a total of 5 entities and 0 collections); 0 nanoseconds spent executing 0 pre-partial-flushes; 0 nanoseconds spent executing 0 partial-flushes (flushing a total of 0 entities and 0 collections) You can see executing 5 JDBC statements; and executing 0 JDBC batches;\nTo enable batch insert in Hibernate, you need to add these configs to application.properties:\n1 2 spring.jpa.properties.hibernate.jdbc.batch_size=10 spring.jpa.properties.hibernate.order_inserts=true And when you run the code again, you will still find the problem LOL (:\n1 2 3 4 5 6 7 8 9 10 11 678067 nanoseconds spent acquiring 1 JDBC connections; 0 nanoseconds spent releasing 0 JDBC connections; 8262300 nanoseconds spent preparing 5 JDBC statements; 4660724 nanoseconds spent executing 5 JDBC statements; 0 nanoseconds spent executing 0 JDBC batches; 0 nanoseconds spent performing 0 L2C puts; 0 nanoseconds spent performing 0 L2C hits; 0 nanoseconds spent performing 0 L2C misses; 3438648 nanoseconds spent executing 1 flushes (flushing a total of 5 entities and 0 collections); 0 nanoseconds spent executing 0 pre-partial-flushes; 0 nanoseconds spent executing 0 partial-flushes (flushing a total of 0 entities and 0 collections) If you set the Hibernate log level to DEBUG, you\u0026rsquo;ll see something interesting:\n1 logging.level.org.hibernate=DEBUG You will see Executing identity-insert immediately repeated five times, which is the size of our list:\n1 2 .... : Executing identity-insert immediately .... : insert into users (email,username) values (?,?) returning id That\u0026rsquo;s weird, right? This happens because when you have an entity with an ID that auto-increments using GenerationType.IDENTITY, each insert statement must be executed immediately to obtain the generated key, making it impossible to batch multiple inserts into a single statement.\n1 2 3 4 5 6 7 8 9 @Entity @Table(name = \u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String username; private String email; } To fix that, you have to change the GeneratedValue strategy to SEQUENCE. This allows Hibernate to use its own sequence generator, which is compatible with batch inserts. It requires additional select statements to get the next value from a database sequence, but this usually has no significant performance impact.\n1 2 3 4 5 6 7 8 9 @Entity @Table(name = \u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue(strategy = GenerationType.SEQUENCE) private Long id; private String username; private String email; } Let\u0026rsquo;s try this and see the logs:\n1 2 3 4 5 6 7 8 9 10 11 1169049 nanoseconds spent acquiring 1 JDBC connections; 0 nanoseconds spent releasing 0 JDBC connections; 13152005 nanoseconds spent preparing 3 JDBC statements; 5535759 nanoseconds spent executing 2 JDBC statements; 2062795 nanoseconds spent executing 1 JDBC batches; 0 nanoseconds spent performing 0 L2C puts; 0 nanoseconds spent performing 0 L2C hits; 0 nanoseconds spent performing 0 L2C misses; 19371806 nanoseconds spent executing 1 flushes (flushing a total of 5 entities and 0 collections); 0 nanoseconds spent executing 0 pre-partial-flushes; 0 nanoseconds spent executing 0 partial-flushes (flushing a total of 0 entities and 0 collections) Success! It works. You can see executing 2 JDBC statements: one to select the next ID (which happens when you use GenerationType.SEQUENCE) and the other for the batch insert (1 JDBC batches).\nFrom 5 to 2 — imagine if you were inserting 100 records. This would make a big difference and have a huge impact on performance.\nConclusion While JPA and Hibernate provide powerful abstractions, understanding their underlying mechanisms is crucial for optimizing performance. By properly configuring batch inserts and being aware of potential pitfalls, you can significantly enhance the efficiency of your database operations, especially when dealing with large datasets.\nRemember, the key to effective use of ORMs lies in balancing their convenience with a deep understanding of their behavior and limitations. Always test and verify your assumptions to ensure your application performs as expected.\n","date":"2025-02-13T00:00:00Z","image":"http://localhost:1313/post/i-hate-orms/image_hu_36ba792a65de24d1.png","permalink":"http://localhost:1313/post/i-hate-orms/","title":"I Hate ORMs: Hibernate Edition"},{"content":"Essential Microservices Design Patterns Microservices architecture has become the standard for building scalable, resilient, and maintainable applications. However, distributed systems bring their own challenges. This post explores essential design patterns that help tackle these challenges effectively.\nCommunication Patterns 1. API Gateway Pattern The API Gateway acts as a single entry point for all clients. It routes requests to the appropriate microservice, aggregates responses, and handles cross-cutting concerns like authentication and rate limiting.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @RestController public class ApiGatewayController { @Autowired private ProductService productService; @Autowired private ReviewService reviewService; @GetMapping(\u0026#34;/products/{id}\u0026#34;) public ProductDetails getProductDetails(@PathVariable Long id) { // Get product information Product product = productService.getProduct(id); // Get reviews for the product List\u0026lt;Review\u0026gt; reviews = reviewService.getReviewsForProduct(id); // Combine data and return return new ProductDetails(product, reviews); } } 2. Circuit Breaker Pattern The Circuit Breaker pattern prevents cascading failures by failing fast when a downstream service is unavailable.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Service public class ProductService { @Autowired private RestTemplate restTemplate; @CircuitBreaker(name = \u0026#34;productService\u0026#34;, fallbackMethod = \u0026#34;getProductFallback\u0026#34;) public Product getProduct(Long id) { return restTemplate.getForObject( \u0026#34;http://product-service/products/\u0026#34; + id, Product.class ); } public Product getProductFallback(Long id, Exception e) { // Return a default product or cached data return new Product(id, \u0026#34;Fallback Product\u0026#34;, \u0026#34;This is a fallback response\u0026#34;, 0.0); } } 3. Saga Pattern The Saga pattern manages failures in distributed transactions by defining compensating actions for each step.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @Service public class OrderSaga { @Autowired private OrderService orderService; @Autowired private PaymentService paymentService; @Autowired private InventoryService inventoryService; @Autowired private ShippingService shippingService; @Transactional public OrderResult createOrder(Order order) { try { // Step 1: Create an order OrderEntity savedOrder = orderService.createOrder(order); try { // Step 2: Process payment Payment payment = paymentService.processPayment(order.getCustomerId(), order.getAmount()); try { // Step 3: Update inventory inventoryService.updateInventory(order.getItems()); try { // Step 4: Schedule shipping Shipping shipping = shippingService.scheduleDelivery(savedOrder); return new OrderResult(savedOrder, payment, shipping); } catch (Exception e) { // Compensate step 3 inventoryService.restoreInventory(order.getItems()); // Compensate step 2 paymentService.refundPayment(payment.getId()); // Compensate step 1 orderService.cancelOrder(savedOrder.getId()); throw e; } } catch (Exception e) { // Compensate step 2 paymentService.refundPayment(payment.getId()); // Compensate step 1 orderService.cancelOrder(savedOrder.getId()); throw e; } } catch (Exception e) { // Compensate step 1 orderService.cancelOrder(savedOrder.getId()); throw e; } } catch (Exception e) { throw new OrderCreationException(\u0026#34;Failed to create order\u0026#34;, e); } } } Data Management Patterns 1. Database per Service Each microservice has its own database, ensuring loose coupling and independent development.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Product Service Database (PostgreSQL) CREATE TABLE products ( id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL, description TEXT, price DECIMAL(10, 2) NOT NULL, stock INTEGER NOT NULL DEFAULT 0 ); // Order Service Database (MongoDB) { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbd7c9d5d3b2c1a7c8f4a1b\u0026#34;), \u0026#34;customerId\u0026#34;: \u0026#34;customer123\u0026#34;, \u0026#34;items\u0026#34;: [ { \u0026#34;productId\u0026#34;: 101, \u0026#34;quantity\u0026#34;: 2, \u0026#34;price\u0026#34;: 29.99 }, { \u0026#34;productId\u0026#34;: 102, \u0026#34;quantity\u0026#34;: 1, \u0026#34;price\u0026#34;: 49.99 } ], \u0026#34;totalAmount\u0026#34;: 109.97, \u0026#34;status\u0026#34;: \u0026#34;PROCESSING\u0026#34;, \u0026#34;createdAt\u0026#34;: ISODate(\u0026#34;2023-08-24T10:15:30Z\u0026#34;) } 2. CQRS (Command Query Responsibility Segregation) Separate read and write operations for better scalability and performance.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // Command side (Writes) @RestController @RequestMapping(\u0026#34;/products/commands\u0026#34;) public class ProductCommandController { @Autowired private ProductCommandService commandService; @PostMapping public ResponseEntity\u0026lt;String\u0026gt; createProduct(@RequestBody ProductCreateCommand command) { String productId = commandService.createProduct(command); return ResponseEntity.ok(productId); } @PutMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;Void\u0026gt; updateProduct(@PathVariable String id, @RequestBody ProductUpdateCommand command) { commandService.updateProduct(id, command); return ResponseEntity.ok().build(); } } // Query side (Reads) @RestController @RequestMapping(\u0026#34;/products/queries\u0026#34;) public class ProductQueryController { @Autowired private ProductQueryService queryService; @GetMapping public ResponseEntity\u0026lt;List\u0026lt;ProductDTO\u0026gt;\u0026gt; getAllProducts() { return ResponseEntity.ok(queryService.findAllProducts()); } @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;ProductDTO\u0026gt; getProduct(@PathVariable String id) { return queryService.findById(id) .map(ResponseEntity::ok) .orElse(ResponseEntity.notFound().build()); } } 3. Event Sourcing Store all changes to the application state as a sequence of events.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @Service public class ProductEventSourcingService { @Autowired private EventStore eventStore; @Autowired private ProductProjection productProjection; public void createProduct(CreateProductCommand command) { ProductCreatedEvent event = new ProductCreatedEvent( command.getProductId(), command.getName(), command.getDescription(), command.getPrice() ); eventStore.save(\u0026#34;product\u0026#34;, command.getProductId(), event); productProjection.apply(event); } public void updateProductPrice(UpdateProductPriceCommand command) { ProductPriceUpdatedEvent event = new ProductPriceUpdatedEvent( command.getProductId(), command.getNewPrice() ); eventStore.save(\u0026#34;product\u0026#34;, command.getProductId(), event); productProjection.apply(event); } public Product getProduct(String productId) { List\u0026lt;Event\u0026gt; events = eventStore.getEvents(\u0026#34;product\u0026#34;, productId); Product product = new Product(productId); for (Event event : events) { if (event instanceof ProductCreatedEvent) { ProductCreatedEvent e = (ProductCreatedEvent) event; product.setName(e.getName()); product.setDescription(e.getDescription()); product.setPrice(e.getPrice()); } else if (event instanceof ProductPriceUpdatedEvent) { ProductPriceUpdatedEvent e = (ProductPriceUpdatedEvent) event; product.setPrice(e.getNewPrice()); } // Handle other events } return product; } } Deployment Patterns 1. Sidecar Pattern Deploy helper services alongside the main service to handle cross-cutting concerns.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion: v1 kind: Pod metadata: name: web-app labels: app: web spec: containers: - name: main-app image: my-web-app:latest ports: - containerPort: 8080 - name: log-collector image: log-collector:latest volumeMounts: - name: logs mountPath: /var/log - name: metrics-collector image: prometheus-agent:latest ports: - containerPort: 9090 volumes: - name: logs emptyDir: {} 2. Blue-Green Deployment Maintain two identical production environments to minimize downtime during deployments.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: application-ingress annotations: kubernetes.io/ingress.class: nginx spec: rules: - host: myapp.example.com http: paths: - path: / pathType: Prefix backend: service: name: green-service # Current active environment port: number: 80 --- # Later, after deploying the blue environment and verifying it works, # update the ingress to point to the blue service apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: application-ingress annotations: kubernetes.io/ingress.class: nginx spec: rules: - host: myapp.example.com http: paths: - path: / pathType: Prefix backend: service: name: blue-service # New active environment port: number: 80 Resilience Patterns 1. Bulkhead Pattern Isolate components to prevent failures from cascading through the system.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Service public class ResilientProductService { @Autowired private RestTemplate restTemplate; @Bulkhead(name = \u0026#34;productService\u0026#34;, type = Bulkhead.Type.THREADPOOL) public Product getProduct(Long id) { return restTemplate.getForObject( \u0026#34;http://product-service/products/\u0026#34; + id, Product.class ); } @Bulkhead(name = \u0026#34;inventoryService\u0026#34;, type = Bulkhead.Type.THREADPOOL) public Inventory getInventory(Long productId) { return restTemplate.getForObject( \u0026#34;http://inventory-service/inventory/product/\u0026#34; + productId, Inventory.class ); } } 2. Retry Pattern Automatically retry failed operations to handle transient failures.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Service public class RetryableOrderService { @Autowired private RestTemplate restTemplate; @Retry(name = \u0026#34;orderService\u0026#34;, fallbackMethod = \u0026#34;createOrderFallback\u0026#34;) public Order createOrder(OrderRequest request) { return restTemplate.postForObject( \u0026#34;http://order-service/orders\u0026#34;, request, Order.class ); } public Order createOrderFallback(OrderRequest request, Exception e) { // Save to local queue for later processing return new Order(null, request.getCustomerId(), \u0026#34;PENDING\u0026#34;, new Date()); } } Conclusion Microservices design patterns help address the inherent challenges of distributed systems. By understanding and applying these patterns appropriately, developers can build more resilient, scalable, and maintainable microservices architectures.\nIt\u0026rsquo;s important to remember that these patterns are tools, not rules. Each has its own trade-offs, and the right pattern depends on your specific requirements and constraints.\nIn future posts, we\u0026rsquo;ll dive deeper into implementation details and explore how these patterns can be combined to solve complex architectural problems.\n","date":"2024-09-25T13:45:00Z","image":"http://localhost:1313/post/microservices-patterns/image_hu_1943bc7741341408.png","permalink":"http://localhost:1313/post/microservices-patterns/","title":"Essential Microservices Design Patterns"},{"content":"Building RESTful APIs with Spring Boot Spring Boot has revolutionized the way we build Java applications, especially when it comes to creating RESTful APIs. In this post, we\u0026rsquo;ll walk through the process of building a simple but robust REST API using Spring Boot.\nSetting Up the Project The easiest way to start a Spring Boot project is by using the Spring Initializer (https://start.spring.io/). For our REST API, we\u0026rsquo;ll need the following dependencies:\nSpring Web Spring Data JPA H2 Database (for development) Lombok (optional, but helpful) Creating the Data Model Let\u0026rsquo;s create a simple entity for our API:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Entity @Data public class Product { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @NotBlank private String name; private String description; @Positive private BigDecimal price; @CreationTimestamp private LocalDateTime createdAt; @UpdateTimestamp private LocalDateTime updatedAt; } Repository Layer Spring Data JPA makes it incredibly easy to create a repository:\n1 2 3 public interface ProductRepository extends JpaRepository\u0026lt;Product, Long\u0026gt; { List\u0026lt;Product\u0026gt; findByNameContaining(String name); } This interface automatically provides methods for CRUD operations, and we\u0026rsquo;ve added a custom query method.\nService Layer The service layer contains our business logic:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Service @RequiredArgsConstructor public class ProductService { private final ProductRepository productRepository; public List\u0026lt;Product\u0026gt; getAllProducts() { return productRepository.findAll(); } public Product getProductById(Long id) { return productRepository.findById(id) .orElseThrow(() -\u0026gt; new ResourceNotFoundException(\u0026#34;Product not found\u0026#34;)); } public Product createProduct(Product product) { return productRepository.save(product); } public Product updateProduct(Long id, Product productDetails) { Product product = getProductById(id); product.setName(productDetails.getName()); product.setDescription(productDetails.getDescription()); product.setPrice(productDetails.getPrice()); return productRepository.save(product); } public void deleteProduct(Long id) { Product product = getProductById(id); productRepository.delete(product); } public List\u0026lt;Product\u0026gt; searchProducts(String keyword) { return productRepository.findByNameContaining(keyword); } } Controller Layer Now let\u0026rsquo;s create the REST endpoints:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @RestController @RequestMapping(\u0026#34;/api/products\u0026#34;) @RequiredArgsConstructor public class ProductController { private final ProductService productService; @GetMapping public List\u0026lt;Product\u0026gt; getAllProducts() { return productService.getAllProducts(); } @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;Product\u0026gt; getProductById(@PathVariable Long id) { Product product = productService.getProductById(id); return ResponseEntity.ok(product); } @PostMapping public ResponseEntity\u0026lt;Product\u0026gt; createProduct(@Valid @RequestBody Product product) { Product createdProduct = productService.createProduct(product); URI location = ServletUriComponentsBuilder.fromCurrentRequest() .path(\u0026#34;/{id}\u0026#34;) .buildAndExpand(createdProduct.getId()) .toUri(); return ResponseEntity.created(location).body(createdProduct); } @PutMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;Product\u0026gt; updateProduct(@PathVariable Long id, @Valid @RequestBody Product productDetails) { Product updatedProduct = productService.updateProduct(id, productDetails); return ResponseEntity.ok(updatedProduct); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; deleteProduct(@PathVariable Long id) { productService.deleteProduct(id); return ResponseEntity.ok().build(); } @GetMapping(\u0026#34;/search\u0026#34;) public List\u0026lt;Product\u0026gt; searchProducts(@RequestParam String keyword) { return productService.searchProducts(keyword); } } Exception Handling To make our API robust, we need proper exception handling:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @ControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(ResourceNotFoundException.class) public ResponseEntity\u0026lt;?\u0026gt; handleResourceNotFoundException(ResourceNotFoundException ex) { Map\u0026lt;String, String\u0026gt; response = Map.of(\u0026#34;error\u0026#34;, ex.getMessage()); return new ResponseEntity\u0026lt;\u0026gt;(response, HttpStatus.NOT_FOUND); } @ExceptionHandler(MethodArgumentNotValidException.class) public ResponseEntity\u0026lt;?\u0026gt; handleValidationExceptions(MethodArgumentNotValidException ex) { Map\u0026lt;String, String\u0026gt; errors = new HashMap\u0026lt;\u0026gt;(); ex.getBindingResult().getFieldErrors().forEach(error -\u0026gt; errors.put(error.getField(), error.getDefaultMessage())); return new ResponseEntity\u0026lt;\u0026gt;(errors, HttpStatus.BAD_REQUEST); } } Testing the API For a comprehensive API, we should have both unit and integration tests:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @SpringBootTest @AutoConfigureMockMvc class ProductControllerTest { @Autowired private MockMvc mockMvc; @Autowired private ObjectMapper objectMapper; @Autowired private ProductRepository productRepository; @Test void shouldCreateProduct() throws Exception { Product product = new Product(); product.setName(\u0026#34;Test Product\u0026#34;); product.setDescription(\u0026#34;Test Description\u0026#34;); product.setPrice(new BigDecimal(\u0026#34;9.99\u0026#34;)); mockMvc.perform(post(\u0026#34;/api/products\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(product))) .andExpect(status().isCreated()) .andExpect(jsonPath(\u0026#34;$.name\u0026#34;).value(\u0026#34;Test Product\u0026#34;)); } // More tests... } Conclusion Spring Boot provides a powerful and efficient way to build RESTful APIs. With minimal configuration, we can focus on our business logic while Spring handles the repetitive tasks. The combination of Spring Boot, Spring Data JPA, and Spring MVC offers a complete toolset for API development.\nIn future posts, we\u0026rsquo;ll explore more advanced features like security, caching, and documentation for Spring Boot APIs.\n","date":"2023-12-10T10:15:00Z","image":"http://localhost:1313/post/spring-boot-rest-api/image_hu_1b3ca765af243167.png","permalink":"http://localhost:1313/post/spring-boot-rest-api/","title":"Building RESTful APIs with Spring Boot"},{"content":"Core Principles of Test-Driven Development Test-Driven Development (TDD) is a software development approach where tests are written before the code they are testing. This article explores the fundamental principles of TDD and how to implement it effectively in your projects.\nThe TDD Cycle: Red, Green, Refactor The TDD approach follows a simple yet powerful cycle:\nRed: Write a failing test for the functionality you want to implement Green: Write just enough code to make the test pass Refactor: Improve the code without changing its functionality This cycle is repeated for each new feature or functionality, ensuring that every line of code is backed by a test.\nExample: TDD in Action Let\u0026rsquo;s see TDD in action with a simple example. Imagine we\u0026rsquo;re creating a calculator application:\nStep 1: Write a failing test 1 2 3 4 5 @Test public void testAddition() { Calculator calculator = new Calculator(); assertEquals(5, calculator.add(2, 3)); } Running this test will fail because we haven\u0026rsquo;t implemented the Calculator class yet.\nStep 2: Write code to make the test pass 1 2 3 4 5 public class Calculator { public int add(int a, int b) { return a + b; } } Now our test passes.\nStep 3: Refactor if necessary In this simple example, there might not be much to refactor. As our calculator grows more complex, we would refactor while ensuring all tests continue to pass.\nBenefits of TDD Higher code quality: Tests catch bugs early in the development process Better design: Writing tests first encourages more modular, loosely coupled code Documentation: Tests serve as living documentation of how code should behave Confidence in changes: Tests provide a safety net when refactoring or adding features Reduced debugging time: Problems are identified at the source Common TDD Pitfalls Over-testing: Writing tests for every line of code, including implementation details Ignoring integration testing: Focusing only on unit tests without testing how components work together Abandoning TDD under pressure: Skipping tests when deadlines approach Testing the wrong things: Writing tests that don\u0026rsquo;t verify important behaviors Tools for TDD in Java JUnit and TestNG: The standard testing frameworks for Java Mockito: For creating mock objects in tests AssertJ: Provides fluent assertions for testing Hamcrest: Matchers that can be combined to create flexible expressions of intent Conclusion Test-Driven Development might seem counterintuitive at first, but it becomes a natural part of the development process with practice. The investment in writing tests first leads to more robust code and can actually speed up development by reducing debugging time and preventing regressions.\nIn future posts, we\u0026rsquo;ll explore more advanced TDD techniques and patterns for specific situations.\n","date":"2023-11-05T14:30:00Z","image":"http://localhost:1313/post/test-driven-development-principles/image_hu_61662e1ec67bc28c.png","permalink":"http://localhost:1313/post/test-driven-development-principles/","title":"Core Principles of Test-Driven Development"},{"content":"Why Related Content Matters Related content sections are a powerful way to keep visitors engaged with your website by suggesting relevant articles they might be interested in. They reduce bounce rates, increase page views, and improve the overall user experience by helping readers discover more of your content.\nHow Hugo Handles Related Content Hugo has a built-in system for identifying and displaying related content based on various factors like tags, categories, and publication dates. Unlike some other platforms that might use complex algorithms or third-party services, Hugo handles this functionality natively.\nConfiguring Related Content in Hugo Step 1: Add Related Content Configuration The first step is to add the related content configuration to your hugo.toml (or config.yaml/config.json):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [related] # Include newer content in the relatedness calculation includeNewer = true # The minimum score a page must have to be considered related threshold = 60 # Convert tags/categories to lowercase before comparison toLower = false [[related.indices]] name = \u0026#34;tags\u0026#34; weight = 100 [[related.indices]] name = \u0026#34;categories\u0026#34; weight = 80 [[related.indices]] name = \u0026#34;date\u0026#34; weight = 10 This configuration tells Hugo:\nTo include newer content in the related content calculation (includeNewer = true) That a page must score at least 60 points to be considered related (threshold = 60) To match tags with a weight of 100, categories with a weight of 80, and consider publication date with a weight of 10 Step 2: Make Sure Your Content is Well-Tagged For Hugo to find related content, your posts need to be properly tagged and categorized. Add tags and categories to the front matter of your Markdown posts:\n1 2 3 4 5 6 --- title: \u0026#34;My Amazing Post\u0026#34; date: 2023-10-01 tags: [\u0026#34;hugo\u0026#34;, \u0026#34;web development\u0026#34;, \u0026#34;jamstack\u0026#34;] categories: [\u0026#34;tutorials\u0026#34;, \u0026#34;web\u0026#34;] --- The more specific and consistent your tagging system is, the better Hugo can match related content.\nStep 3: Styling the Related Content Section If you\u0026rsquo;re using the Hugo Stack theme like I am, the theme already includes basic styling for the related content section. However, you can customize it further by adding custom CSS:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Custom styles for related content */ .article-list--compact.related-content { margin-top: 2rem; border-top: 1px solid var(--card-separator-color); padding-top: 1.5rem; } .article-list--compact.related-content .article-title { font-size: 1.1rem; font-weight: 600; } .related-content header { margin-bottom: 1rem; } .related-content header h2 { font-size: 1.4rem; color: var(--accent-color); } Add this CSS to your site\u0026rsquo;s custom CSS file (usually in static/css/custom.css) and make sure it\u0026rsquo;s included in your site configuration.\nBest Practices for Effective Related Content 1. Use Specific and Consistent Tagging Tags are the primary way Hugo identifies related content. Use specific, descriptive tags and be consistent with your tagging system.\n2. Organize Content with Categories Categories provide another dimension for relating content. While tags can be more specific and numerous, categories should represent broader classifications of your content.\n3. Review and Adjust Related Content Settings Monitor how your related content appears on your site. If you find that Hugo is suggesting unrelated content, you might need to:\nIncrease the threshold value Adjust the weights of different indices Improve your tagging strategy 4. Consider Manual Related Content Links For especially important connections that Hugo might miss, you can manually add links to related content within your posts:\n1 2 3 ## Related Articles - [Getting Started with Hugo](/posts/getting-started-with-hugo/) - [Advanced Hugo Templates](/posts/advanced-hugo-templates/) Example: How Related Content Calculation Works Let\u0026rsquo;s say we have three posts:\nPost A: Tags: [hugo, markdown, templates], Categories: [tutorials] Post B: Tags: [hugo, css, design], Categories: [tutorials] Post C: Tags: [wordpress, cms], Categories: [reviews]\nWhen displaying related content for Post A:\nPost B scores: 100 (shared tag \u0026ldquo;hugo\u0026rdquo;) + 80 (shared category \u0026ldquo;tutorials\u0026rdquo;) = 180 Post C scores: 0 (no shared tags or categories) Since Post B exceeds our threshold of 60, it will be shown as related content, while Post C will not.\nConclusion Implementing related content in your Hugo site is a straightforward but powerful way to enhance the user experience and keep visitors engaged with your content. By properly configuring Hugo\u0026rsquo;s related content settings and maintaining a consistent tagging system, you can automatically suggest relevant articles to your readers and increase the time they spend on your site.\nBy using the built-in functionality of Hugo and the Hugo Stack theme, you can have an elegant related content section without any third-party services or complex plugins.\n","date":"2023-10-15T00:00:00Z","image":"http://localhost:1313/post/adding-related-content-to-hugo/cover_hu_a0bc2e9bccc7302f.png","permalink":"http://localhost:1313/post/adding-related-content-to-hugo/","title":"How to Add Related Content to Your Hugo Theme"},{"content":"SOLID Principles in Java: A Comprehensive Guide The SOLID principles are a set of five design principles that help developers create more maintainable, flexible, and scalable software. These principles were introduced by Robert C. Martin (Uncle Bob) and have become fundamental guidelines for object-oriented software design.\nWhat are SOLID Principles? SOLID is an acronym where each letter represents a principle:\nS: Single Responsibility Principle (SRP) O: Open/Closed Principle (OCP) L: Liskov Substitution Principle (LSP) I: Interface Segregation Principle (ISP) D: Dependency Inversion Principle (DIP) Let\u0026rsquo;s explore each principle with practical Java examples.\nSingle Responsibility Principle (SRP) A class should have only one reason to change.\nThis principle states that a class should be responsible for a single task or functionality.\nBad Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class UserService { public void registerUser(User user) { // Validate user if (user.getEmail() == null || !user.getEmail().contains(\u0026#34;@\u0026#34;)) { throw new IllegalArgumentException(\u0026#34;Invalid email\u0026#34;); } // Save user to database String sql = \u0026#34;INSERT INTO users (name, email) VALUES (?, ?)\u0026#34;; try (Connection conn = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost/mydb\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); PreparedStatement stmt = conn.prepareStatement(sql)) { stmt.setString(1, user.getName()); stmt.setString(2, user.getEmail()); stmt.executeUpdate(); } catch (SQLException e) { throw new RuntimeException(e); } // Send confirmation email sendEmail(user.getEmail(), \u0026#34;Welcome\u0026#34;, \u0026#34;Welcome to our platform!\u0026#34;); } private void sendEmail(String to, String subject, String body) { // Code to send email System.out.println(\u0026#34;Email sent to \u0026#34; + to); } } Good Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 public class UserValidator { public void validate(User user) { if (user.getEmail() == null || !user.getEmail().contains(\u0026#34;@\u0026#34;)) { throw new IllegalArgumentException(\u0026#34;Invalid email\u0026#34;); } } } public class UserRepository { public void save(User user) { String sql = \u0026#34;INSERT INTO users (name, email) VALUES (?, ?)\u0026#34;; try (Connection conn = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost/mydb\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); PreparedStatement stmt = conn.prepareStatement(sql)) { stmt.setString(1, user.getName()); stmt.setString(2, user.getEmail()); stmt.executeUpdate(); } catch (SQLException e) { throw new RuntimeException(e); } } } public class EmailService { public void sendWelcomeEmail(User user) { sendEmail(user.getEmail(), \u0026#34;Welcome\u0026#34;, \u0026#34;Welcome to our platform!\u0026#34;); } private void sendEmail(String to, String subject, String body) { // Code to send email System.out.println(\u0026#34;Email sent to \u0026#34; + to); } } public class UserService { private final UserValidator validator; private final UserRepository repository; private final EmailService emailService; public UserService(UserValidator validator, UserRepository repository, EmailService emailService) { this.validator = validator; this.repository = repository; this.emailService = emailService; } public void registerUser(User user) { validator.validate(user); repository.save(user); emailService.sendWelcomeEmail(user); } } Open/Closed Principle (OCP) Software entities should be open for extension but closed for modification.\nThis principle emphasizes that you should be able to extend a class\u0026rsquo;s behavior without modifying it.\nBad Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class Rectangle { private double width; private double height; // Getters and setters public double area() { return width * height; } } public class Circle { private double radius; // Getters and setters public double area() { return Math.PI * radius * radius; } } public class AreaCalculator { public double calculateArea(Object shape) { if (shape instanceof Rectangle) { Rectangle rectangle = (Rectangle) shape; return rectangle.area(); } else if (shape instanceof Circle) { Circle circle = (Circle) shape; return circle.area(); } throw new IllegalArgumentException(\u0026#34;Unsupported shape\u0026#34;); } } Good Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public interface Shape { double area(); } public class Rectangle implements Shape { private double width; private double height; // Getters and setters @Override public double area() { return width * height; } } public class Circle implements Shape { private double radius; // Getters and setters @Override public double area() { return Math.PI * radius * radius; } } public class Triangle implements Shape { private double base; private double height; // Getters and setters @Override public double area() { return 0.5 * base * height; } } public class AreaCalculator { public double calculateArea(Shape shape) { return shape.area(); } } Liskov Substitution Principle (LSP) Objects of a superclass should be replaceable with objects of its subclasses without affecting the correctness of the program.\nThis principle is about ensuring that a derived class can stand in for its base class without causing issues.\nBad Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 public class Rectangle { protected double width; protected double height; public void setWidth(double width) { this.width = width; } public void setHeight(double height) { this.height = height; } public double getWidth() { return width; } public double getHeight() { return height; } public double area() { return width * height; } } public class Square extends Rectangle { @Override public void setWidth(double width) { super.setWidth(width); super.setHeight(width); } @Override public void setHeight(double height) { super.setHeight(height); super.setWidth(height); } } // Client code public void testRectangle(Rectangle rectangle) { rectangle.setWidth(5); rectangle.setHeight(4); assert rectangle.area() == 20; // This fails for Square } Good Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public interface Shape { double area(); } public class Rectangle implements Shape { private double width; private double height; public Rectangle(double width, double height) { this.width = width; this.height = height; } public double getWidth() { return width; } public double getHeight() { return height; } @Override public double area() { return width * height; } } public class Square implements Shape { private double side; public Square(double side) { this.side = side; } public double getSide() { return side; } @Override public double area() { return side * side; } } Interface Segregation Principle (ISP) Clients should not be forced to depend on methods they do not use.\nThis principle advises creating specific interfaces rather than one general-purpose interface.\nBad Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public interface Worker { void work(); void eat(); void sleep(); } public class Robot implements Worker { @Override public void work() { System.out.println(\u0026#34;Robot is working\u0026#34;); } @Override public void eat() { // Robots don\u0026#39;t eat, but we\u0026#39;re forced to implement this method throw new UnsupportedOperationException(\u0026#34;Robots don\u0026#39;t eat\u0026#34;); } @Override public void sleep() { // Robots don\u0026#39;t sleep, but we\u0026#39;re forced to implement this method throw new UnsupportedOperationException(\u0026#34;Robots don\u0026#39;t sleep\u0026#34;); } } Good Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public interface Workable { void work(); } public interface Eatable { void eat(); } public interface Sleepable { void sleep(); } public class Human implements Workable, Eatable, Sleepable { @Override public void work() { System.out.println(\u0026#34;Human is working\u0026#34;); } @Override public void eat() { System.out.println(\u0026#34;Human is eating\u0026#34;); } @Override public void sleep() { System.out.println(\u0026#34;Human is sleeping\u0026#34;); } } public class Robot implements Workable { @Override public void work() { System.out.println(\u0026#34;Robot is working\u0026#34;); } } Dependency Inversion Principle (DIP) High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions.\nThis principle is about decoupling modules through abstractions.\nBad Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class EmailNotifier { public void sendEmail(String to, String subject, String body) { // Code to send email System.out.println(\u0026#34;Email sent to \u0026#34; + to); } } public class UserRegistrationService { private EmailNotifier emailNotifier = new EmailNotifier(); public void registerUser(User user) { // Save user to database // Send notification emailNotifier.sendEmail(user.getEmail(), \u0026#34;Welcome\u0026#34;, \u0026#34;Welcome to our platform!\u0026#34;); } } Good Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public interface NotificationService { void sendNotification(String recipient, String subject, String body); } public class EmailNotifier implements NotificationService { @Override public void sendNotification(String recipient, String subject, String body) { // Code to send email System.out.println(\u0026#34;Email sent to \u0026#34; + recipient); } } public class SMSNotifier implements NotificationService { @Override public void sendNotification(String recipient, String subject, String body) { // Code to send SMS System.out.println(\u0026#34;SMS sent to \u0026#34; + recipient); } } public class UserRegistrationService { private final NotificationService notificationService; public UserRegistrationService(NotificationService notificationService) { this.notificationService = notificationService; } public void registerUser(User user) { // Save user to database // Send notification notificationService.sendNotification(user.getEmail(), \u0026#34;Welcome\u0026#34;, \u0026#34;Welcome to our platform!\u0026#34;); } } Conclusion The SOLID principles provide a framework for writing maintainable and scalable code. When applied correctly, they help to:\nCreate more reusable code Reduce technical debt Make the codebase more robust to changes Improve readability and understanding of the code Make testing easier While these principles might seem abstract at first, with practice, they become invaluable tools in a developer\u0026rsquo;s arsenal for creating high-quality software.\nIn future posts, we\u0026rsquo;ll dive deeper into design patterns that build upon these SOLID principles to solve common software design challenges.\n","date":"2023-09-18T11:30:00Z","image":"http://localhost:1313/post/solid-principles/image_hu_28a203c39f0e77a8.png","permalink":"http://localhost:1313/post/solid-principles/","title":"SOLID Principles in Java: A Comprehensive Guide"}]